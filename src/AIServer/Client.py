from __future__ import annotations

import sys
import xml.etree.ElementTree as ET
from asyncio import CancelledError, Queue, QueueEmpty, sleep
from urllib.parse import urljoin
from zipfile import ZipFile

import httpx
import openai_python_client.api.chat.create_chat_completion as api
from openai_python_client import Client
from openai_python_client.models.user_message import UserMessage
from openai_python_client.models.user_message_role import UserMessageRole

from .__init__ import LLAMAFILE_MODEL, LLAMAFILE_SIZE, logger
from .health import AIHealth

# generated by protoc
from .job.job_pb2 import JobRequest, JobResponse, SupportedLanguage

# from .templates import summarize_t  # type: ignore
from .templates import length_t  # type: ignore
from .templates import name_t  # type: ignore
from .templates import short_t  # type: ignore
from .templates import story_l_t  # type: ignore
from .templates import story_m_t  # type: ignore
from .templates import story_s_t  # type: ignore
from .templates import change_language

# ARGS
HOST = "127.0.0.1"
PORT = 50052


class AIClient:
    def __init__(self, srv_host: str, srv_port: int):
        self.srv_host: str = srv_host
        self.srv_port: int = srv_port
        self.srv_url: str = f"http://{self.srv_host}:{self.srv_port}/v1"
        self.client: Client = Client(self.srv_url, verify_ssl=False)
        self.health_interval: int = 15
        self.ai_health = AIHealth.UNKNOWN
        self.grammar_quotes: str = (
            ZipFile(sys.argv[0]).read("AIServer/schemas/quote.gbnf").decode("utf-8")
        )
        self.grammar_digit: str = (
            ZipFile(sys.argv[0]).read("AIServer/schemas/digit.gbnf").decode("utf-8")
        )

    async def test_art_description_job(self) -> None:
        language: SupportedLanguage = SupportedLanguage.ENGLISH
        hash_code: int = 0
        xml_def: str = (
            r"""
<saveable Class="Building_Art">
  <id>SculptureGrand5070</id>
  <pos>(60,0,66)</pos>
  <map>0</map>
  <health>195</health>
  <stuff>WoodLog</stuff>
  <faction>Faction14</faction>
  <questTags IsNull="True" />
  <spawnedTick>59</spawnedTick>
  <quality>Masterwork</quality>
  <sourcePrecept>null</sourcePrecept>
  <everSeenByPlayer>True</everSeenByPlayer>
  <tile>0</tile>
  <art>Son</art>
  <seed>533422075</seed>
  <taleRef>null</taleRef>
</saveable>
""".strip()
        )
        title: str = ""
        description: str = ""
        job: JobRequest.ArtDescriptionJob = JobRequest.ArtDescriptionJob(
            hash_code=hash_code,
            xml_def=xml_def,
            title=title,
            description=description,
        )
        await self.do_art_description_job(job, language=language)

    async def start(
        self,
        input_queue: Queue[tuple[int, JobRequest]],
        output_queue: Queue[tuple[int, JobResponse]],
    ) -> None:
        sleep_for: float = 0.5

        while True:
            try:
                request_job_id: int
                request: JobRequest

                # Get a "work item" out of the queue.
                request_job_id, request = input_queue.get_nowait()

                # switch supported request types
                response: JobResponse = JobResponse()
                response.job_id = request_job_id
                match request.WhichOneof("job_payload"):  # type: ignore
                    case "art_description_job":
                        art_description_response = await self.do_art_description_job(
                            request.art_description_job,
                            request.language,
                        )
                        response.art_description_response.CopyFrom(  # type: ignore
                            art_description_response
                        )
                    case _:  # type: ignore
                        pass

                # Put the result into the output queue
                await output_queue.put((response.job_id, response))
            except QueueEmpty:
                # Sleep for the "sleep_for" seconds
                await sleep(sleep_for)

    async def do_art_description_job(
        self,
        art_job: JobRequest.ArtDescriptionJob,
        language: SupportedLanguage,
    ) -> JobResponse.ArtDescriptionResponse:
        hash_code: int = art_job.hash_code
        title: str = art_job.title
        description: str = art_job.description
        xml_def: str = art_job.xml_def

        # load language-specific templates
        change_language(language)

        # extract def and quality from xml
        try:
            xml_def_et: ET.Element = ET.fromstring(xml_def)

            # Safely retrieve and process the 'def' element
            defin_xml = xml_def_et.find("def")
            if isinstance(defin_xml, ET.Element) and defin_xml.text:
                defin = defin_xml.text
            else:
                defin = "Art"

            # Safely retrieve and process the 'stuff' element
            stuff_xml = xml_def_et.find("stuff")
            if isinstance(stuff_xml, ET.Element) and stuff_xml.text:
                stuff = stuff_xml.text
            else:
                stuff = "Steel"

            # Safely retrieve the 'quality' element
            quality = xml_def_et.find("quality")
            if isinstance(quality, ET.Element) and quality.text:
                quality = quality.text
            else:
                quality = "Good"

            # Substitute the values in the template
            short_desc: str = short_t.substitute(defin=defin, stuff=stuff, quality=quality)  # type: ignore
        except:
            short_desc: str = "Type: Art\nMaterial: Steel\nQuality: Good"

        # do summarize
        # summarize_num: int = ceil(len(ET.fromstring(xml_def)) / 5)
        # message: str = summarize_t.substitute(num=summarize_num, xml=xml_def)  # type: ignore
        # reply: str | None = await self.do_chat(message, grammar=self.grammar_quotes)  # type: ignore
        # summarization: str = (
        #     reply if reply else description
        # )  # temporary, will incorporate description into generation later

        # do random story length
        message: str = length_t.substitute(info=short_desc)  # type: ignore
        reply: str | None = await self.do_chat(message, grammar=self.grammar_digit)  # type: ignore
        try:
            if reply:
                story_len: int = int(reply)
            else:
                story_len: int = 4  # default to 4 sentences
        except ValueError:
            story_len: int = 4

        # do story
        if LLAMAFILE_SIZE == "mini":
            message: str = story_s_t.substitute(len=story_len, title=title, description=short_desc + "\n\n" + description)  # type: ignore
        elif LLAMAFILE_SIZE == "small":
            message: str = story_m_t.substitute(len=story_len, title=title, description=short_desc + "\n\n" + description)  # type: ignore
        else:
            message: str = story_l_t.substitute(len=story_len, title=title, description=short_desc + "\n\n" + description)  # type: ignore
        reply: str | None = await self.do_chat(message, grammar=self.grammar_quotes)  # type: ignore
        story: str = reply if reply else description  # fallback

        # do name
        message: str = name_t.substitute(pas=story)  # type: ignore
        reply: str | None = await self.do_chat(message, grammar=self.grammar_quotes)  # type: ignore
        name: str = reply if reply else title  # fallback

        name = self.strip_quotes(name)
        story = self.strip_quotes(story)

        # replace all mentions of old title with new title
        story = story.replace(title, name).strip()

        # return result
        return JobResponse.ArtDescriptionResponse(
            hash_code=hash_code,
            xml_def=xml_def,
            title=name,
            description=story,
        )

    async def do_chat(self, content: str, grammar: str | None = None):
        message: UserMessage = UserMessage(
            role=UserMessageRole.USER,
            content=content.strip(),
        )
        request: api.CreateChatCompletionRequest = api.CreateChatCompletionRequest(
            messages=[message],
            model=str(LLAMAFILE_MODEL),
            temperature=0.7,
        )

        # additional properties
        if grammar:
            request.additional_properties["grammar"] = grammar
        request.additional_properties["dynatemp_range"] = 0.3
        request.additional_properties["repeat_penalty"] = 1.05
        request.additional_properties["stop"] = [
            "<|end|>",
            "<|endoftext|>",
            "<|im_end|>",
            "\n",
        ]

        logger.debug(f"Request:\n{request.to_dict()}")
        response: api.CreateChatCompletionResponse | None = await api.asyncio(
            client=self.client,
            body=request,
        )
        if not response:
            return None
        logger.debug(f"Response:\n{response.to_dict()}")
        reply: str | None = response.choices[0].message.content
        if not reply:
            return None
        if "<|end|>" in reply:
            reply = reply.replace("<|end|>", "")
        if "<|endoftext|>" in reply:
            reply = reply.replace("<|endoftext|>", "")
        if "<|im_end|>" in reply:
            reply = reply.replace("<|im_end|>", "")
        return reply.strip()

    # GET /health: Returns the current state of the server:
    # * {"status": "loading model"} if the model is still being loaded.
    # * {"status": "error"} if the model failed to load.
    # * {"status": "ok"} if the model is successfully loaded and the server is ready for further requests mentioned below.
    async def check_ai_health(self) -> None:
        try:
            r = await self.client.get_async_httpx_client().get(
                url=urljoin(self.srv_url, "/health"), timeout=5
            )
            if r.status_code == 200:
                json_data = r.json()
                logger.debug(json_data)
                status = json_data.get("status", "")
                if status == "loading model":
                    self.ai_health = AIHealth.STARTING
                elif status == "error":
                    self.ai_health = AIHealth.ERROR
                elif status == "ok":
                    self.ai_health = AIHealth.HEALTHY
                else:
                    self.ai_health = AIHealth.UNKNOWN
            else:
                self.ai_health = AIHealth.ERROR
        except httpx.ReadError:
            logger.error("HealthCheck: Read Exception")
            self.ai_health = AIHealth.OFFLINE
        except httpx.TimeoutException:
            logger.error("HealthCheck: TimeoutException")
            self.ai_health = AIHealth.OFFLINE

    @staticmethod
    def strip_quotes(s: str) -> str:
        s = s.strip()
        # Find the last quote
        last_quote = s.rfind('"')

        if last_quote == -1:
            # No quotes found
            return s

        # Find the second last quote
        second_last_quote = s.rfind('"', 0, last_quote)

        if second_last_quote == -1:
            # Only one quote found
            return s

        # Return the string without the outermost quotes
        return s[second_last_quote + 1 : last_quote]


async def run(
    input_queue: Queue[tuple[int, JobRequest]],
    output_queue: Queue[tuple[int, JobResponse]],
):
    global client
    client = AIClient(HOST, PORT)
    try:
        while client.ai_health != AIHealth.HEALTHY:
            await sleep(5)
            await client.check_ai_health()
        # await client.test_art_description_job()
        await client.start(input_queue, output_queue)
        logger.info(f"Client connected to {HOST}:{PORT}")
    except CancelledError:
        await client.client.get_async_httpx_client().aclose()
        logger.info("Client gracefully shut down")
