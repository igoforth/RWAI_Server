from __future__ import annotations

from asyncio import CancelledError, Queue, QueueEmpty, sleep
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timezone
from pprint import pformat

from google.protobuf.duration_pb2 import Duration
from google.protobuf.timestamp_pb2 import Timestamp
from grpc.aio import RpcContext, server

from .__init__ import logger

# generated by protoc
from .job.job_pb2 import JobRequest, JobResponse
from .job.job_pb2_grpc import JobManagerServicer, add_JobManagerServicer_to_server

# from .client import client
# from .health import AIHealth


# from grpclib.channelz.service import Channelz
# from grpclib.health.check import ServiceCheck
# from grpclib.health.service import OVERALL, Health


HOST = "127.0.0.1"
PORT = 50051


class JobManager(JobManagerServicer):

    def __init__(
        self,
        input_queue: Queue[tuple[int, JobRequest]],
        output_queue: Queue[tuple[int, JobResponse]],
    ):
        self.input_queue: Queue[tuple[int, JobRequest]] = input_queue
        self.output_queue: Queue[tuple[int, JobResponse]] = output_queue

    async def JobService(self, request: JobRequest, context: RpcContext) -> JobResponse:
        request_timestamp: datetime = request.time.ToDatetime(tzinfo=timezone.utc)
        request_job_id: int = request.job_id
        sleep_for: float = 0.5
        logger.debug("AIServer got job!")

        # Print request
        logger.debug(pformat(request))

        # Put the request into the input queue
        await self.input_queue.put((request_job_id, request))

        # Wait for the job to be processed and get the result
        while True:
            response_job_id: int
            response: JobResponse

            # Get the response from the output queue
            response_job_id, response = await self.output_queue.get()

            if response_job_id == request_job_id:
                break
            else:
                # Put the job back into the output queue if it's not the result we're waiting for
                await self.output_queue.put((response_job_id, response))

            if context.cancelled():
                raise CancelledError

        # Finalize the job response
        duration: Duration = Duration()
        duration.FromTimedelta(datetime.now(timezone.utc) - request_timestamp)
        response.duration.CopyFrom(duration)

        # Send the reply
        return response


# async def health_test():
#     if client:
#         await client.check_ai_health()
#         if client.ai_health == AIHealth.HEALTHY:
#             return True
#     return False


async def run(
    input_queue: Queue[tuple[int, JobRequest]],
    output_queue: Queue[tuple[int, JobResponse]],
):
    # health_check = ServiceCheck(health_test)
    # services_list = [
    # JobManager(input_queue, output_queue),
    # Health({OVERALL: [health_check]}),
    # Channelz(),
    # ]
    # services = ServerReflection.extend(services_list)
    global ai_server
    ai_server = server(ThreadPoolExecutor(max_workers=10))
    add_JobManagerServicer_to_server(JobManager(input_queue, output_queue), ai_server)
    ai_server.add_insecure_port(f"{HOST}:{PORT}")
    try:
        await ai_server.start()
        logger.info(f"Serving on {HOST}:{PORT}")
        await ai_server.wait_for_termination()
    except CancelledError:
        await ai_server.stop(None)
        logger.info("Server gracefully shut down")
