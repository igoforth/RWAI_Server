from __future__ import annotations

import argparse
import collections
import logging
import os
import pathlib
import platform
import signal
import sys
import time
import traceback
from asyncio import (ALL_COMPLETED, CancelledError, Queue, Task, TimeoutError,
                     all_tasks, create_subprocess_exec, create_task,
                     current_task, ensure_future, gather, get_event_loop,
                     sleep, wait, wait_for)
from asyncio.subprocess import DEVNULL, PIPE
from functools import partial
from typing import Any, Coroutine

os_name, os_release, os_version = (
    platform.system(),
    platform.release(),
    platform.version(),
)

# logging
logger = logging.getLogger(__name__)
formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
stderr_handler = logging.StreamHandler(sys.stderr)
stderr_handler.setLevel(logger.getEffectiveLevel())
stderr_handler.setFormatter(formatter)
logger.addHandler(stderr_handler)
logger.propagate = False

# arg parsing
parser = argparse.ArgumentParser(description="Set logger level")
parser.add_argument(
    "--loglevel",
    choices=["DEBUG", "INFO", "WARNING"],
    default="INFO",
    help="Set the logging level",
    type=str,
    required=True,
)
args = parser.parse_args()
logger.setLevel(args.loglevel)

# import health
from . import client, server
# generated by protoc
from .job.job_pb2 import JobRequest, JobResponse

MAX_INTERVAL = 30
RETRY_HISTORY = 3


def get_largest_file(directory: pathlib.Path) -> pathlib.Path:
    # Initialize variables to store the name and size of the largest file
    largest_file = pathlib.Path()
    largest_size = 0

    # Iterate over all files in the provided directory
    for file in pathlib.Path(directory).rglob("*"):
        if file.is_file():  # Ensure it is a file
            file_size = file.stat().st_size

            # Check if the current file is the largest so far
            if file_size > largest_size:
                largest_size = file_size
                largest_file = file

    return largest_file

LLAMAFILE_TEMPLATES: dict[str, str] = {
    "mini": r""" "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}" """.strip(),  # bootstrap downloads special "0.3" finetune with different template
    "small": r""" "{{ bos_token }}{% for message in messages %}{{'<|' + message['role'] + '|>' + '\n' + message['content'] + '<|end|>\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|assistant|>\n' }}{% else %}{{ eos_token }}{% endif %}" """.strip(),  # still use phi-3-small-128k template even though bootstrap downloads smaller phi-3-medium-4k
    # "medium": r""" "{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\n' + message['content'] + '<|end|>' + '\n' + '<|assistant|>' + '\n'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\n'}}{% endif %}{% endfor %}" """.strip(),
    "medium": "phi3",
}

# ARGS
LLAMAFILE_FILENAME = "llamafile.com" if os_name == "Windows" else "llamafile"
LLAMAFILE_PATH: pathlib.Path = pathlib.Path(os.getcwd()) / "bin" / LLAMAFILE_FILENAME
LLAMAFILE_MODEL: pathlib.Path = get_largest_file(
    pathlib.Path(os.getcwd()) / "models"
).relative_to(pathlib.Path(os.getcwd()))
LLAMAFILE_SIZE: str | None = next(
    (key for key in ["medium", "small", "mini"] if key in str(LLAMAFILE_MODEL)),
    None,
)
LLAMAFILE_TEMPLATE: str | None = LLAMAFILE_TEMPLATES.get(str(LLAMAFILE_SIZE), None)
LLAMAFILE_PARAMS_LIST: list[str] = (
    [
        "--host",
        "127.0.0.1",
        "--port",
        "50052",
        "-ngl",
        "9999",
        "--server",
        "--nobrowser",
    ]
    + (["--chat-template", LLAMAFILE_TEMPLATE] if LLAMAFILE_TEMPLATE else [])
    + [
        "-c",
        "4096",
        "-cb",
        "-m",
        str(LLAMAFILE_MODEL),
    ]
)
logger.debug(f"Executing with params: {' '.join(LLAMAFILE_PARAMS_LIST)}")


async def run_llama_forever():
    """Capture output (stdout and stderr) while running external command."""
    stderr_filepath = pathlib.Path("llama_stderr.log")
    if stderr_filepath.exists():
        stderr_filepath.unlink()
    else:
        stderr_filepath.touch()
    # stderr_file = open(stderr_filepath, "wb")

    proc = await create_subprocess_exec(
        LLAMAFILE_PATH,
        *LLAMAFILE_PARAMS_LIST,
        stdout=PIPE,
        stderr=DEVNULL,
    )
    sleep_for: float = 0.5

    try:
        while True:
            # if proc.stdout.at_eof() and stderr_file.closed:
            #     break
            if proc.stdout.at_eof():
                break

            try:
                out = await wait_for(proc.stdout.read(2048), 0.1)
            except TimeoutError:
                await sleep(sleep_for)
            else:
                logger.debug(f"[AI Server] {out.decode().strip()}")
            # try:
            #     err = await asyncio.wait_for(proc.stderr.read(2048), 0.1)
            # except asyncio.TimeoutError:
            #     pass
            # else:
            #     logger.debug(f"[stderr] {err.decode().strip()}")

    except CancelledError:
        logger.info("AI gracefully shut down")
    finally:
        await proc.communicate()
        # stderr_file.flush()
        # stderr_file.close()
        # logger.debug(f'{LLAMAFILE_PATH} {" ".join(LLAMAFILE_PARAMS_LIST)} exited with {proc.returncode}')


def supervise(
    func: partial[Coroutine[Any, Any, None]],
    name: str | None = None,
    retry_history: int = RETRY_HISTORY,
    max_interval: int = MAX_INTERVAL,
):
    """Simple wrapper function that automatically tries to name tasks"""
    if name is None:
        if hasattr(func, "__name__"):  # raw func
            name = func.__name__
        elif hasattr(func, "func"):  # partial
            name = func.func.__name__
    return create_task(
        supervisor(
            func,
            name,
            retry_history,
            max_interval,
        ),
        name=name,
    )


async def supervisor(
    func: function,
    name: str,
    retry_history: int = RETRY_HISTORY,
    max_interval: int = MAX_INTERVAL,
):
    """Takes a noargs function that creates a coroutine, and repeatedly tries
    to run it. It stops is if it thinks the coroutine is failing too often or
    too fast."""
    start_times = collections.deque([float("-inf")], maxlen=retry_history)
    while True:
        start_times.append(time.monotonic())
        try:
            return await func()
        except Exception:
            if min(start_times) > time.monotonic() - max_interval:
                logger.critical(
                    f"Failure in task {current_task().get_name()!r}."
                    " Is it in a restart loop?"
                )
                # we tried our best, this coroutine really isn't working.
                # We should try to shutdown gracefully by setting a global flag
                # that other coroutines should periodically check and stop if they
                # see that it is set.
                raise_graceful_exit()
            else:
                logger.error(name, "failed, will retry. Failed because:")
                traceback.print_exc()


class GracefulExit(SystemExit):
    code = 1


def raise_graceful_exit(*args):
    raise GracefulExit()


async def main_async(
    iq: Queue[tuple[int, JobRequest]],
    oq: Queue[tuple[int, JobResponse]],
):
    tasks: list[Task[Any]] = [
        supervise(run_llama_forever),
        supervise(partial(server.run, iq, oq)),
        supervise(partial(client.run, iq, oq)),
    ]
    await wait(
        tasks,
        # Only stop when all coroutines have completed
        # -- this allows for a graceful shutdown
        # Alternatively use FIRST_EXCEPTION to stop immediately
        return_when=ALL_COMPLETED,
    )
    return tasks

def main():
    iq: Queue[tuple[int, JobRequest]] = Queue()
    oq: Queue[tuple[int, JobResponse]] = Queue()

    loop = get_event_loop()
    signal.signal(signal.SIGINT, raise_graceful_exit)
    signal.signal(signal.SIGTERM, raise_graceful_exit)

    try:
        tasks = ensure_future(main_async(iq, oq), loop=loop)
        loop.run_until_complete(tasks)
    except GracefulExit:
        logger.info("Got signal: SIGINT, shutting down.")
    finally:
        tasks = all_tasks(loop=loop)
        for t in tasks:
            t.cancel()
        loop.run_until_complete(gather(*tasks, return_exceptions=True))
        loop.close()
